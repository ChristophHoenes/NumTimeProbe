{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/research/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "config.json: 100%|██████████| 1.66k/1.66k [00:00<00:00, 3.36MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 443M/443M [00:18<00:00, 23.5MB/s] \n",
      "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['aggregation_classifier.bias', 'aggregation_classifier.weight', 'column_output_bias', 'column_output_weights', 'output_bias', 'output_weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TapasConfig, TapasForQuestionAnswering\n",
    "\n",
    "# for example, the base sized model with default SQA configuration\n",
    "# model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\")\n",
    "\n",
    "# or, the base sized model with WTQ configuration\n",
    "config = TapasConfig.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "#tapas-large-finetuned-wtq\n",
    "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n",
    "\n",
    "# or, the base sized model with WikiSQL configuration\n",
    "#config = TapasConfig(\"google-base-finetuned-wikisql-supervised\")\n",
    "#model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 490/490 [00:00<00:00, 1.08MB/s]\n",
      "vocab.txt: 100%|██████████| 262k/262k [00:00<00:00, 852kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 154/154 [00:00<00:00, 355kB/s]\n",
      "config.json: 100%|██████████| 1.52k/1.52k [00:00<00:00, 3.54MB/s]\n",
      "/opt/conda/envs/research/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2762: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/conda/envs/research/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1561: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2054, 2003,  ...,    0,    0,    0],\n",
       "        [ 101, 2129, 2116,  ...,    0,    0,    0],\n",
       "        [ 101, 2054, 2003,  ...,    0,    0,    0]]), 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'numeric_values': tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]]), 'numeric_values_scale': tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TapasTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"google/tapas-base\"\n",
    "tokenizer = TapasTokenizer.from_pretrained(model_name)\n",
    "\n",
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
    "queries = [\n",
    "    \"What is the name of the first actor?\",\n",
    "    \"How many movies has George Clooney played in?\",\n",
    "    \"What is the total number of movies?\",\n",
    "]\n",
    "answer_coordinates = [[(0, 0)], [(2, 1)], [(0, 1), (1, 1), (2, 1)]]\n",
    "answer_text = [[\"Brad Pitt\"], [\"69\"], [\"209\"]]\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "inputs = tokenizer(\n",
    "    table=table,\n",
    "    queries=queries,\n",
    "    answer_coordinates=answer_coordinates,\n",
    "    answer_text=answer_text,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TableQuestionAnsweringOutput(loss=tensor(0.8520, grad_fn=<AddBackward0>), logits=tensor([[-10000., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.,  ..., -10000., -10000., -10000.]],\n",
       "       grad_fn=<ViewBackward0>), logits_aggregation=tensor([[ 0.1940,  0.3279,  0.4199, -0.1130],\n",
       "        [ 0.1130, -0.3987, -0.3263, -0.3344],\n",
       "        [ 0.5499, -0.2853, -0.5349,  0.5817]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "outputs = model(\n",
    "            input_ids=inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            token_type_ids=inputs.token_type_ids,\n",
    "            labels=inputs.labels,\n",
    "            numeric_values=inputs.numeric_values,\n",
    "            numeric_values_scale=inputs.numeric_values_scale,\n",
    "            float_answer=torch.tensor([[torch.nan], [69], [209]]),\n",
    "        )\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 443M/443M [00:04<00:00, 109MB/s]  \n",
      "tokenizer_config.json: 100%|██████████| 490/490 [00:00<00:00, 1.17MB/s]\n",
      "vocab.txt: 100%|██████████| 262k/262k [00:00<00:00, 881kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 154/154 [00:00<00:00, 397kB/s]\n",
      "/opt/conda/envs/research/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2762: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/conda/envs/research/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1561: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actors</th>\n",
       "      <th>Number of movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brad Pitt</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonardo Di Caprio</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George Clooney</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Actors Number of movies\n",
       "0           Brad Pitt               87\n",
       "1  Leonardo Di Caprio               53\n",
       "2      George Clooney               69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What is the name of the first actor?\n",
      "Predicted answer: Brad Pitt\n",
      "How many movies has George Clooney played in?\n",
      "Predicted answer: COUNT > 69\n",
      "What is the total number of movies?\n",
      "Predicted answer: SUM > 87, 53, 69\n"
     ]
    }
   ],
   "source": [
    "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"google/tapas-base-finetuned-wtq\"\n",
    "model = TapasForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = TapasTokenizer.from_pretrained(model_name)\n",
    "\n",
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
    "queries = [\n",
    "    \"What is the name of the first actor?\",\n",
    "    \"How many movies has George Clooney played in?\",\n",
    "    \"What is the total number of movies?\",\n",
    "]\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "    inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n",
    ")\n",
    "\n",
    "# let's print out the results:\n",
    "id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3: \"COUNT\"}\n",
    "aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n",
    "\n",
    "answers = []\n",
    "for coordinates in predicted_answer_coordinates:\n",
    "    if len(coordinates) == 1:\n",
    "        # only a single cell:\n",
    "        answers.append(table.iat[coordinates[0]])\n",
    "    else:\n",
    "        # multiple cells\n",
    "        cell_values = []\n",
    "        for coordinate in coordinates:\n",
    "            cell_values.append(table.iat[coordinate])\n",
    "        answers.append(\", \".join(cell_values))\n",
    "\n",
    "display(table)\n",
    "print(\"\")\n",
    "for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n",
    "    print(query)\n",
    "    if predicted_agg == \"NONE\":\n",
    "        print(\"Predicted answer: \" + answer)\n",
    "    else:\n",
    "        print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4097985/126750372.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was too old on your system - pyarrow 10.0.1 is the current minimum supported version as of this release.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "tokenizer_config.json: 100%|██████████| 717/717 [00:00<00:00, 2.19MB/s]\n",
      "vocab.json: 100%|██████████| 777k/777k [00:00<00:00, 1.94MB/s]\n",
      "merges.txt: 100%|██████████| 442k/442k [00:00<00:00, 27.7MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.06M/2.06M [00:00<00:00, 17.5MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 564/564 [00:00<00:00, 1.28MB/s]\n",
      "config.json: 100%|██████████| 1.02k/1.02k [00:00<00:00, 2.31MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 4.55G/4.55G [03:43<00:00, 20.4MB/s]\n",
      "generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 275kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "\n",
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
    "queries = [\n",
    "    \"What is the name of the first actor?\",\n",
    "    \"How many movies has George Clooney played in?\",\n",
    "    \"What is the total number of movies?\",\n",
    "]\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seeklhy/codes-1b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"seeklhy/codes-1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_text = \"\"\"\n",
    "table movie , columns = [ movie.mid ( int | primary key | comment : movie id | values : 101 ,\n",
    "102 ) , movie.title ( text | values : Gone with the Wind , Star Wars ) , movie.year ( int |\n",
    "values : 1939 , 1977 ) , movie.director ( text | values : Victor Fleming , George Lucas ) ]\n",
    "table reviewer , columns = [ reviewer.rid ( int | primary key | comment : reviewer id | values :\n",
    "201 , 202 ) , reviewer.name ( text | values : Sarah Martinez , Daniel Lewis ) ]\n",
    "table rating , columns = [ rating.rid ( int | comment : reviewer id | values : 201 , 202 ) ,\n",
    "rating.mid ( int | comment : movie id | values : 101 ,106 ) , rating.stars ( int | comment : rating\n",
    "stars | values : 2 , 4 ) , rating.ratingdate ( date | values : 2011-01-22 , 2011-01-27 ) ]\n",
    "foreign keys :\n",
    "rating.rid = reviewer.rid\n",
    "rating.mid = movie.mid\n",
    "matched values :\n",
    "reviewer.name ( Sarah Martinez )\n",
    "Question:\n",
    "What are the names of all directors whose movies have been reviewed by Sarah Martinez?\n",
    "\"\"\"\n",
    "\n",
    "#queries.append(\"What is the average of column number of movies given that the column actor has value Pumuckel?\")\n",
    "\n",
    "in_text = f\"\"\"table movie , columns = [ movie.Actor ( text | primary key | comment : name of | values : Olaf Scholz ,\n",
    "Sinatra ) , movie.Number_of_Movies ( int | values : 9 , 12 ) ] Question: {queries[-1]}\"\"\"\n",
    "\n",
    "in_text = queries[-1]\n",
    "\n",
    "inputs = tokenizer(in_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"What is the average of column number of movies given that the column actor has value Pumuckel?\\nSELECT AVG(column_number) FROM movies WHERE column_actor = 'Pumuckel';<|endoftext|>\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "tokenizer.batch_decode(model.generate(**inputs, max_new_tokens=64, do_sample=False))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(__ table id titlemovie_id,int ) string key ) auto\\'\\' id ) auto : 1,0, 102,, movie.name ( string | primary : \"host with the Wind, The Wars ), movie.year ( int | valuesvalues : 2977, 2947 ), movie.rating ( text | values : <irgin Hleming, <orge Lucas ),\\n\\n actor, columns = [ reviewer.rid ( int | primary key | comment : reviewer id |\\n :\\n101, 202 ), reviewer.name ( text | values : <ah,inez, <leewis ),\\ntable rating, columns = [ rating.rid ( int | primary : reviewer id | values : 201, 202 ), ratingrating.mid ( int | comment : movie id | values : 101, 02 ), rating.rating ( int | values : stars || | values : 5, 4 ) ] rating.date ( ( date | comment : 2012-01-00, 2011-01-23 ) ]\\ntable key (\\nmovie.rid ( reviewer.rid\\nrating.mid = movie.mid\\n\\n by :\\nrating.rid = Sarah Martinez,,movie  WhatWhat is the top of the theors who movies have been r by moreah Martinez?\\nSELECT'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs['logits'].argmax(dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
